{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp L3A_user_model.py\n",
    "# from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-cover",
   "metadata": {},
   "source": [
    "# 03A user churn model\n",
    "\n",
    "> packaging churn model, given records similar to user_profile (combined data and feature generated from various sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-indianapolis",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns; sns.set_theme()\n",
    "from collections import defaultdict\n",
    "\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "import tsfresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-metropolitan",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-letter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def load_directory_files_dict(dir_path)->dict:\n",
    "    'Load all pkl files in the directory into dict'\n",
    "    L1file_list = os.listdir(path_load)\n",
    "    L1file_list = [i for i in L1file_list if not i.startswith(\".\") and i.endswith('.pkl')]\n",
    "    L1name_list = [i.split(\"_\")[0]+\"_\"+i.split(\"_\")[1].replace(\".pkl\",\"\") for i in L1file_list]\n",
    "\n",
    "    dt = {}\n",
    "    for name, key in zip(L1file_list, L1name_list):\n",
    "        dt[key] = pd.read_pickle(os.path.join(path_load,name))\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-cutting",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "path_load = os.path.join(\"Data\",\"L2\")\n",
    "path_save = os.path.join(\"Data\",\"L3\")\n",
    "\n",
    "dt = load_directory_files_dict(path_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-scratch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msisdn</th>\n",
       "      <th>churn</th>\n",
       "      <th>train__age</th>\n",
       "      <th>train__contract</th>\n",
       "      <th>train__internet_service</th>\n",
       "      <th>train__account_start_year</th>\n",
       "      <th>planning_area</th>\n",
       "      <th>train__month_delta</th>\n",
       "      <th>census__med_income</th>\n",
       "      <th>census__avg_income</th>\n",
       "      <th>...</th>\n",
       "      <th>web__starhub__sum_values</th>\n",
       "      <th>web__starhub__mean</th>\n",
       "      <th>web__starhub__absolute_sum_of_changes</th>\n",
       "      <th>web__singtel__absolute_sum_of_changes</th>\n",
       "      <th>web__starhub__linear_trend__attr_\"intercept\"</th>\n",
       "      <th>web__singtel__linear_trend__attr_\"intercept\"</th>\n",
       "      <th>web__singtel__minimum</th>\n",
       "      <th>web__starhub__benford_correlation</th>\n",
       "      <th>web__starhub__minimum</th>\n",
       "      <th>web__singtel__benford_correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6048764759382</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>TOA PAYOH</td>\n",
       "      <td>25</td>\n",
       "      <td>1500</td>\n",
       "      <td>5089.771035</td>\n",
       "      <td>...</td>\n",
       "      <td>1779.0</td>\n",
       "      <td>296.500000</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>133.571429</td>\n",
       "      <td>630.857143</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.473221</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.057715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>891319344217</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>TOA PAYOH</td>\n",
       "      <td>117</td>\n",
       "      <td>1500</td>\n",
       "      <td>5089.771035</td>\n",
       "      <td>...</td>\n",
       "      <td>4656.0</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>2144.0</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>919.714286</td>\n",
       "      <td>244.857143</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-0.026776</td>\n",
       "      <td>310.0</td>\n",
       "      <td>0.383169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99251853671</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>TOA PAYOH</td>\n",
       "      <td>151</td>\n",
       "      <td>1500</td>\n",
       "      <td>5089.771035</td>\n",
       "      <td>...</td>\n",
       "      <td>3502.0</td>\n",
       "      <td>583.666667</td>\n",
       "      <td>2862.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>444.523810</td>\n",
       "      <td>293.380952</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.662261</td>\n",
       "      <td>17.0</td>\n",
       "      <td>-0.282165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9795194264183</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>TOA PAYOH</td>\n",
       "      <td>73</td>\n",
       "      <td>1500</td>\n",
       "      <td>5089.771035</td>\n",
       "      <td>...</td>\n",
       "      <td>4214.0</td>\n",
       "      <td>702.333333</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>947.476190</td>\n",
       "      <td>609.190476</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.055723</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.077998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5833245602906</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>TOA PAYOH</td>\n",
       "      <td>15</td>\n",
       "      <td>1500</td>\n",
       "      <td>5089.771035</td>\n",
       "      <td>...</td>\n",
       "      <td>3069.0</td>\n",
       "      <td>511.500000</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>237.571429</td>\n",
       "      <td>386.809524</td>\n",
       "      <td>311.0</td>\n",
       "      <td>0.140976</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-0.110172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          msisdn  churn  train__age  train__contract  train__internet_service  \\\n",
       "0  6048764759382      0          44                0                        1   \n",
       "1   891319344217      0          56                1                        1   \n",
       "2    99251853671      0          26                0                        1   \n",
       "3  9795194264183      0          48                0                        0   \n",
       "4  5833245602906      0          52                0                        0   \n",
       "\n",
       "   train__account_start_year planning_area  train__month_delta  \\\n",
       "0                       2018     TOA PAYOH                  25   \n",
       "1                       2010     TOA PAYOH                 117   \n",
       "2                       2007     TOA PAYOH                 151   \n",
       "3                       2014     TOA PAYOH                  73   \n",
       "4                       2018     TOA PAYOH                  15   \n",
       "\n",
       "   census__med_income  census__avg_income  ...  web__starhub__sum_values  \\\n",
       "0                1500         5089.771035  ...                    1779.0   \n",
       "1                1500         5089.771035  ...                    4656.0   \n",
       "2                1500         5089.771035  ...                    3502.0   \n",
       "3                1500         5089.771035  ...                    4214.0   \n",
       "4                1500         5089.771035  ...                    3069.0   \n",
       "\n",
       "   web__starhub__mean  web__starhub__absolute_sum_of_changes  \\\n",
       "0          296.500000                                 1213.0   \n",
       "1          776.000000                                 2144.0   \n",
       "2          583.666667                                 2862.0   \n",
       "3          702.333333                                 1985.0   \n",
       "4          511.500000                                 1605.0   \n",
       "\n",
       "   web__singtel__absolute_sum_of_changes  \\\n",
       "0                                 2009.0   \n",
       "1                                 2499.0   \n",
       "2                                 1306.0   \n",
       "3                                  995.0   \n",
       "4                                  764.0   \n",
       "\n",
       "   web__starhub__linear_trend__attr_\"intercept\"  \\\n",
       "0                                    133.571429   \n",
       "1                                    919.714286   \n",
       "2                                    444.523810   \n",
       "3                                    947.476190   \n",
       "4                                    237.571429   \n",
       "\n",
       "   web__singtel__linear_trend__attr_\"intercept\"  web__singtel__minimum  \\\n",
       "0                                    630.857143                  184.0   \n",
       "1                                    244.857143                  140.0   \n",
       "2                                    293.380952                   76.0   \n",
       "3                                    609.190476                  176.0   \n",
       "4                                    386.809524                  311.0   \n",
       "\n",
       "   web__starhub__benford_correlation  web__starhub__minimum  \\\n",
       "0                           0.473221                   79.0   \n",
       "1                          -0.026776                  310.0   \n",
       "2                           0.662261                   17.0   \n",
       "3                           0.055723                  440.0   \n",
       "4                           0.140976                   82.0   \n",
       "\n",
       "   web__singtel__benford_correlation  \n",
       "0                           0.057715  \n",
       "1                           0.383169  \n",
       "2                          -0.282165  \n",
       "3                           0.077998  \n",
       "4                          -0.110172  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['user_profile'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-stage",
   "metadata": {},
   "source": [
    "## target/features seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dt['user_profile'].pop('churn')\n",
    "X_columns = dt['user_profile'].columns\n",
    "X = dt['user_profile']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-florida",
   "metadata": {},
   "source": [
    "## sklearn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-athletics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data\\\\L3\\\\RF_churn_model.joblib']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up a pipeline with a feature selection preprocessor that\n",
    "# drop unnessary features\n",
    "# then uses a RandomForestClassifier to train the model.\n",
    "\n",
    "dropping_columns = ['msdidn','planning_area']\n",
    "drop_idx = [idx for idx, i in enumerate(X_columns) if i in dropping_columns]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "      (\"select\", ColumnTransformer([('drop','drop', drop_idx)], remainder='passthrough')),  # filtering for index columns\n",
    "      ('classification', RandomForestClassifier( \n",
    "          class_weight='balanced_subsample', max_depth=4,\n",
    "                       min_samples_leaf=0.03, n_estimators=500, n_jobs=-1,\n",
    "                       random_state=0) # model\n",
    "      )\n",
    "    ])\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Export the classifier to a file\n",
    "joblib.dump(pipeline, os.path.join(path_save, 'RF_churn_model.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-albert",
   "metadata": {},
   "source": [
    "### prediction \n",
    "with the saved sklearn joblib pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-player",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(X[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-swing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zig] *",
   "language": "python",
   "name": "conda-env-zig-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
